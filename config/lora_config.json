{
    "lora_rank": 256,
    "lora_alpha": 512,
    "lora_dropout": 0.1,
    "lora_module": ["q_proj", "v_proj", "o_proj", "fc1", "fc2"],
    "uselora": true
}
